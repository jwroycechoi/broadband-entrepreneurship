---
title: "Database Inspect and Merge"
author: "Jaewon Royce Choi"
date: "6/11/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Broadband and Entrepreneurship

This document lays out the data handling process of multiple databases related to broadband availability, speed, and entrepreneurship of Texas. Databases used here are as follows:

* Microsoft Broadband Availability Dataset
* Measurement Lab (M-Lab) Datasets Exported via Google BigQuery
* GoDaddy Venture Density & Demographic Dataset
* Texas Sole Proprietors Data
* IRR Rural Index

In the following sections, I will import, clean, and set up the aforementioned datasets to be joined by _county_.

Install and call packages used for the folloiwng process.

```{r package, echo=TRUE}
rm(list = ls())   ## Clear the workspace
setwd("~/Dropbox/Works/Broadband-Entrepreneurship/Broadband Data")    ## Set working directory

#install.packages("tidyverse")
#install.packages("ggplot2")
#install.packages("DBI")
#devtools::install_github("rstats-db/bigrquery")
library(tidyverse)
library(ggplot2)
library(DBI)
```

***

## Microsoft Broadband Availability Dataset

Microsoft dataset is available in its [GitHub repository](https://github.com/microsoft/USBroadbandUsagePercentages). Therefore, we will directly import its dataset from the URL.

```{r Microsoft Import, echo=TRUE}
## Import the Dataset
ms_broadband <- read.csv("https://raw.githubusercontent.com/microsoft/USBroadbandUsagePercentages/master/dataset/broadband_data.csv", header = T)

## Inspect Structure
str(ms_broadband)
```

Note that the percentage variables are imported as factors. We need them to be in the form of integers. Converting factors directly to numeric vectors using `as.numeric()` would result in loss of information. Following the methods suggested [here](https://stackoverflow.com/a/3418192/11199930), the code below converts `BROADBAND.AVAILABILITY.PER.FCC` and `BROADBAND.USAGE` to numeric values.

```{r Microsoft Data Manipulation, echo=TRUE}
## Create new variabes in numeric form
ms_broadband <- ms_broadband %>% 
  mutate(pct_broadband_FCC = as.numeric(levels(BROADBAND.AVAILABILITY.PER.FCC))[BROADBAND.AVAILABILITY.PER.FCC],
         pct_broadband_MS = as.numeric(levels(BROADBAND.USAGE))[BROADBAND.USAGE])

## Confirm the change
str(ms_broadband)

```

Next step is to filter out information on the states other than Texas

```{r Microsoft TX}
## Filtering TX
ms_broadband_tx <- ms_broadband %>% 
  filter(ST == "TX") %>% droplevels() # Deletes unused levels in factor variables in a dataset

## Inspect the result
str(ms_broadband_tx)


```

## GoDaddy Dataset

The GoDaddy dataset has been used by researchers (Mossberger, Tolbert, & LaCombe, 2020) for studying local entrepreneurship represented by actual adoption and usage of the Internet. The dataset includes venture density variables in various time frames. Furthermore, the dataset includes numbers of important demographic/economic factors derived from the American Community Survey estimates.

In the following section, I will import, inspect and set up the dataset for further join with other databases.

```{r GoDaddy Data Import, echo=TRUE}
## Import the Dataset
godaddy_cbsa <- read.csv("GoDaddy_CBSA.csv", header = T)    # GoDaddy dataset at the unit of Core Based Statistical Area (CBSA) defined by U.S. Department of Housing and Urban Development
godaddy_county <- read.csv("GoDaddy_County.csv", header = T)    # GoDaddy dataset at the county level

## Inspect Structure
str(godaddy_cbsa)
str(godaddy_county)

```

The GoDaddy dataset also has to be filtered to include only Texas data. Since we are at the moment only interested in county level information, the filtering will only be conducted to the county level dataset. The county level dataset has a variable named _cfips_, which is a FIPS code. FIPS code idnetifies Texas by the [first two digit: '48'](https://www.dshs.texas.gov/chs/info/info_txco.shtm).

```{r GoDaddy Texas Filter}
## Filtering Texas using FIPS code
str(godaddy_county)

godaddy_county_tx <- godaddy_county %>% 
  filter(startsWith(as.character(cfips), "48")) %>% # Filter Texas
  mutate(population = as.numeric(gsub(",","",as.character(population)))) %>% # Convert population from factor to numeric
  separate(county, into = c("county", "state"), sep = ", ", remove = T) %>% # Separate county variable which had state and county data at the same time
  droplevels()  # Drop unused levels from factor variables

## Inspect Structure
str(godaddy_county_tx)

```

## M-Lab Datasets

Measurement Lab (M-Lab) datasets consists of user reported download (DL) and upload (UL) speed by geographical information. The easiest way to access and retrieve data from the database is by making queries via Google BigQuery platform using Standard SQL statements. Currently M-Lab suggests using the _Unified View_ dataset to researchers. The datasets from the following time frames are retrived through BigQuery using SQL statements shared by M-Lab team modified to match the time frames. 

* September 2019
* October 2019
* November 2019
* December 2019

These time frames are initially selected because it matches the ones provided in the GoDaddy dataset. GoDaddy dataset provides venture density information in several time frame. While there are several time frames in 2018, the intervals are inconsistent. Since the time frames of 2019 are equally distanced (i.e., monthly) from September to December, this time frame was initially selected for M-Lab data retrieval.

In this section, I will import the retrieved M-Lab datasets and clean them.

```{r M-Lab Data Import and Clean}
## Import the Dataset
mlab_sept <- read.csv("Mlab_State_All_Sept_2019.csv", header = T)
mlab_oct <- read.csv("Mlab_State_All_Oct_2019.csv", header = T)
mlab_nov <- read.csv("Mlab_State_All_Nov_2019.csv", header = T)
mlab_dec <- read.csv("Mlab_State_All_Dec_2019.csv", header = T)

## Inspect Structure
str(mlab_sept)
str(mlab_oct)
str(mlab_nov)
str(mlab_dec)

#### Cleaning and Filtering the Dataset ####
## September 2019 ##
mlab_sept_tx <- mlab_sept %>% 
  filter(state == "TX") %>% 
  select(-c("UL_3_state","UL_3_county_name","DL_10_state","DL_10_county_name","UL_1_state","UL_1_county_name","DLmed_state","DLmed_county_name","ULmed_state","ULmed_county_name","ul_sample_state","ul_sample_county_name","dl_sample_state","dl_sample_county_name")) %>% 
  mutate(county = paste(as.character(county_name), "County", sep = " "),
         frac_over_25DL = 1 - frac_under_25mbpsDL,
         frac_over_3UL = 1 - frac_under_3mbpsUL) %>% 
  droplevels()

str(mlab_sept_tx)

## October 2019 ##
mlab_oct_tx <- mlab_oct %>% 
  filter(state == "TX") %>% 
  select(-c("UL_3_state","UL_3_county_name","DL_10_state","DL_10_county_name","UL_1_state","UL_1_county_name","DLmed_state","DLmed_county_name","ULmed_state","ULmed_county_name","ul_sample_state","ul_sample_county_name","dl_sample_state","dl_sample_county_name")) %>% 
  mutate(county = paste(as.character(county_name), "County", sep = " "),
         frac_over_25DL = 1 - frac_under_25mbpsDL,
         frac_over_3UL = 1 - frac_under_3mbpsUL) %>% 
  droplevels()

## November 2019 ##
mlab_nov_tx <- mlab_nov %>% 
  filter(state == "TX") %>% 
  select(-c("UL_3_state","UL_3_county_name","DL_10_state","DL_10_county_name","UL_1_state","UL_1_county_name","DLmed_state","DLmed_county_name","ULmed_state","ULmed_county_name","ul_sample_state","ul_sample_county_name","dl_sample_state","dl_sample_county_name")) %>% 
  mutate(county = paste(as.character(county_name), "County", sep = " "),
         frac_over_25DL = 1 - frac_under_25mbpsDL,
         frac_over_3UL = 1 - frac_under_3mbpsUL) %>% 
  droplevels()

## December 2019 ##
mlab_dec_tx <- mlab_dec %>% 
  filter(state == "TX") %>% 
  select(-c("UL_3_state","UL_3_county_name","DL_10_state","DL_10_county_name","UL_1_state","UL_1_county_name","DLmed_state","DLmed_county_name","ULmed_state","ULmed_county_name","ul_sample_state","ul_sample_county_name","dl_sample_state","dl_sample_county_name")) %>% 
  mutate(county = paste(as.character(county_name), "County", sep = " "),
         frac_over_25DL = 1 - frac_under_25mbpsDL,
         frac_over_3UL = 1 - frac_under_3mbpsUL) %>% 
  droplevels()

```

## Texas Sole Proprietors Dataset

This dataset contains information of sole proprietors number provided by the Bureau of Business Research at $IC^{2}$ Institute. The information is presented at the county level.

```{r Texas Sole Proprietor Dataset Import and Clean}
## Import the Dataset
tx_proprietor <- read_csv("Sole-Proprietors-tx-combined.csv")

## Inspect the Structure
str(tx_proprietor)

```

This dataset's variables are straighforward as it was pre-cleaned on Excel spreadsheet.

## IRR Rural Index

This dataset contains information of IRR index at the county level. The index calculates the extent to which a certain county could be considered as _'rural'_. Smaller the value of the index, more rural the county is considered to be.

There are two datasets that contains data from 2000 and 2010. I will import these datasets, filter for Texas and set up for a final merge of all datasets we have.

```{r IRR Rural Index Import and Clean}
## Import the Dataset
rural_2000 <- read_csv("IRR-rural-2000.csv")
rural_2010 <- read_csv("IRR-rural-2010.csv")

## Inspect Structure
str(rural_2000)
str(rural_2010)

#### Clean the Datasets ####
## Filter Texas counties using FIPS code ##

rural_2000_tx <- rural_2000 %>% 
  filter(startsWith(as.character(FIPS2000), "48")) %>% 
  separate(`County Name`, into = c("county", "state"), sep = ", ", remove = T)

rural_2010_tx <- rural_2010 %>% 
  filter(startsWith(as.character(FIPS2010), "48")) %>% 
  separate(`County Name`, into = c("county", "state"), sep = ", ", remove = T)

## Inspect Structure
str(rural_2000_tx)
str(rural_2010_tx)

```

## Merge into Single Dataset at the County Level

In this section, I will join all the datasets I have cleand and processed above into a single dataset containing all the information at the county level rows. The names of the datasets created from the process above are as follows

* `ms_broadband_tx`
* `godaddy_county_tx`
* `mlab_sept_tx`; `mlab_oct_tx`; `mlab_nov_tx`; `mlab_dec_tx`
* `tx_proprietor`
* `rural_2000_tx`; `rural_2010_tx`

I will first inspect the datasets quickly to see if row counts of all datasets are matched since it is possible some of them (especially M-Lab datasets) have less/missing observations. Afterwards, I'll join the datasets into one.

```{r Inspect Dataset Structures and Merge}

#### Inspect the Number of Observations ####
tibble(MS = count(ms_broadband_tx)$n, godaddy = count(godaddy_county_tx)$n,
       mlabsept = count(mlab_sept_tx)$n, mlaboct = count(mlab_oct_tx)$n, mlabnov = count(mlab_nov_tx)$n, mlabdec = count(mlab_dec_tx)$n,
       txprop = count(tx_proprietor)$n, irr2000 = count(rural_2000_tx)$n, irr2010 = count(rural_2010_tx)$n)

```

Several missing observation from M-Lab datasets and one missing from GoDaddy dataset here. Therefore, it is critical that these datasets are not used as a reference dataset for joining. Folloiwng code chunk will use `join` functions of `dplyr`.

```{r Merge Datsets}
#### Join the Datasets ####

str(ms_broadband_tx)
str(godaddy_county_tx)
str(mlab_dec_tx)
str(tx_proprietor)
str(rural_2000_tx)

## The variables to match from each datasets are
## ms_broadband_tx$COUNTY.ID          Integer
## ms_broadband_tx$COUNTY.NAME        Factor    ("____ County")
## godaddy_county_tx$cfips            Integer
## godaddy_county_tx$county           Character ("____ County")
## mlab datasets$county               Character ("____ County")
## tx_proprietor$county               Character ("____ County")
## rural datasets#county              Character ("____ County")

## Create a character vector for ms_broadband_tx dataset to minimize potential error beforehand
ms_broadband_tx <- ms_broadband_tx %>% mutate(county = as.character(COUNTY.NAME))
str(ms_broadband_tx)

## Nested left_joins on IRR dataset
names(mlab_sept_tx) <- paste(names(mlab_sept_tx), ".sept", sep = "")
names(mlab_oct_tx) <- paste(names(mlab_oct_tx), ".oct", sep = "")
names(mlab_nov_tx) <- paste(names(mlab_nov_tx), ".nov", sep = "")
names(mlab_dec_tx) <- paste(names(mlab_dec_tx), ".dec", sep = "")

tx_bb_entrepreneur_merged <- left_join(rural_2000_tx, rural_2010_tx, by = "county") %>% 
  left_join(., tx_proprietor, by = "county") %>% 
  left_join(., ms_broadband_tx, by = "county") %>% 
  left_join(., godaddy_county_tx, by = "county") %>% 
  left_join(., mlab_sept_tx, by = c("county" = "county.sept")) %>% 
  left_join(., mlab_oct_tx, by = c("county" = "county.oct")) %>% 
  left_join(., mlab_nov_tx, by = c("county" = "county.nov")) %>% 
  left_join(., mlab_dec_tx, by = c("county" = "county.dec"))

str(tx_bb_entrepreneur_merged)

head(tx_bb_entrepreneur_merged, 20)

## Export the dataset into csv

write_csv(tx_bb_entrepreneur_merged, "Broadband-Entrepreneurship-TX-merged.csv")

```

